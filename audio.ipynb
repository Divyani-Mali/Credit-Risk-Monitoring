{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfqXU3kb6m4Z/KJxmwjuMg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Divyani-Mali/Credit-Risk-Monitoring/blob/main/audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQJQZ_tpBtmE",
        "outputId": "781332c6-1a5d-4dfc-ce44-5a06064be610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.61.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install librosa\n",
        "!pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mea0t0tbCCHY",
        "outputId": "6cdb23c5-88a3-4f3e-df48-4ba65989e462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir('/content/drive/MyDrive/HACKATHON')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9L_PoZpGWbe",
        "outputId": "f371b656-5cab-4a11-9109-111228c5f99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Copy of archive (4).zip']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Path to your file in Google Drive\n",
        "zip_file = '/content/drive/MyDrive/archive (4).zip'\n",
        "extracted_folder = '/content/audio_data/'\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_folder)\n",
        "\n",
        "print(f\"Files extracted to {extracted_folder}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOGyAvONEjcc",
        "outputId": "d29014a3-fd6a-4c96-cca6-45c57ae49694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted to /content/audio_data/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Path to the folder where the audio files are extracted\n",
        "audio_folder = '/content/audio_data/'  # adjust if necessary\n",
        "\n",
        "# List all audio files in the folder\n",
        "audio_files = [f for f in os.listdir(audio_folder) if f.endswith('.wav')]  # assuming .wav files\n",
        "\n",
        "# Function to convert an audio file to MFCCs\n",
        "def extract_mfcc(file_path):\n",
        "    # Load the audio file\n",
        "    audio, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "    # Extract MFCCs (Mel-frequency cepstral coefficients)\n",
        "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
        "\n",
        "    # Normalize MFCC\n",
        "    mfcc = np.mean(mfcc, axis=1)\n",
        "\n",
        "    return mfcc\n",
        "\n",
        "# Extract MFCCs for all audio files\n",
        "audio_data = []\n",
        "for file in audio_files:\n",
        "    file_path = os.path.join(audio_folder, file)\n",
        "    mfcc_features = extract_mfcc(file_path)\n",
        "    audio_data.append(mfcc_features)\n",
        "\n",
        "# Convert the list into a NumPy array\n",
        "audio_data = np.array(audio_data)\n",
        "\n",
        "print(audio_data.shape)  # Check the shape of the extracted features\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DubB3qRERzfQ",
        "outputId": "99388709-27ca-42c7-dece-e0c9595c6b74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_folder = '/content/audio_data/train'  # Adjust if necessary\n",
        "print(os.listdir(train_folder))  # List files in the 'train' folder\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL_5aPGFTGMI",
        "outputId": "03d4bb8d-1aaf-4791-801b-f9a04d503cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fake', 'real']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Paths for fake and real subfolders\n",
        "fake_folder = '/content/audio_data/train/fake'\n",
        "real_folder = '/content/audio_data/train/real'\n",
        "\n",
        "# Function to extract MFCC from an audio file\n",
        "def extract_mfcc(file_path):\n",
        "    # Load the audio file\n",
        "    audio, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "    # Extract MFCCs (Mel-frequency cepstral coefficients)\n",
        "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
        "\n",
        "    # Normalize MFCC by averaging over time frames\n",
        "    mfcc = np.mean(mfcc, axis=1)\n",
        "\n",
        "    return mfcc\n",
        "\n",
        "# Function to process files and return the extracted features and labels\n",
        "def process_audio_file(file_path, label):\n",
        "    mfcc_features = extract_mfcc(file_path)\n",
        "    return mfcc_features, label\n",
        "\n",
        "# List all audio files in both 'fake' and 'real' folders\n",
        "audio_data = []\n",
        "labels = []  # Labels for classification (fake = 0, real = 1)\n",
        "\n",
        "# Create a thread pool for parallel processing\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    # Process fake audio files in parallel\n",
        "    fake_files = [os.path.join(fake_folder, file) for file in os.listdir(fake_folder) if file.endswith('.wav')]\n",
        "    fake_results = executor.map(lambda file: process_audio_file(file, 0), fake_files)\n",
        "\n",
        "    # Process real audio files in parallel\n",
        "    real_files = [os.path.join(real_folder, file) for file in os.listdir(real_folder) if file.endswith('.wav')]\n",
        "    real_results = executor.map(lambda file: process_audio_file(file, 1), real_files)\n",
        "\n",
        "    # Collect results\n",
        "    for result in fake_results:\n",
        "        audio_data.append(result[0])\n",
        "        labels.append(result[1])\n",
        "\n",
        "    for result in real_results:\n",
        "        audio_data.append(result[0])\n",
        "        labels.append(result[1])\n",
        "\n",
        "# Convert the list into a NumPy array for audio data and labels\n",
        "audio_data = np.array(audio_data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Check the shape of the extracted features and labels\n",
        "print(audio_data.shape)\n",
        "print(labels.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyipN6X-TRSb",
        "outputId": "52157385-0f27-42e3-c092-525bf32cac49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13185, 13)\n",
            "(13185,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(audio_data, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "print(X_train.shape, X_test.shape)  # Check the shape of the splits\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EKsSb92T0WN",
        "outputId": "b77fc328-83ba-4756-eb24-79a28b676756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9229, 13) (3956, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Normalize the MFCC features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "TyNiKw5lWIat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialize and train the classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kub8pUd2WKyI",
        "outputId": "85944cb4-13e7-43bc-dbb8-28b1dda24b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.96840242669363\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98      3244\n",
            "           1       0.98      0.84      0.91       712\n",
            "\n",
            "    accuracy                           0.97      3956\n",
            "   macro avg       0.97      0.92      0.94      3956\n",
            "weighted avg       0.97      0.97      0.97      3956\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "UF2MAG8qWTHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYDz04exW1L7",
        "outputId": "1742c66e-e7a2-4ac8-e92d-0e4febb982c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.96840242669363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "BuwC9tO8XILi",
        "outputId": "9c7d4691-588f-442e-8f56-6e7cc1f63ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer (13 features)\n",
        "model.add(Dense(64, input_dim=13, activation='relu'))\n",
        "model.add(Dropout(0.3))  # Dropout for regularization\n",
        "\n",
        "# Hidden layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer (binary classification)\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "KZduvwfoXN-k",
        "outputId": "823781a2-407e-4c84-a2eb-eda109885b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,169\u001b[0m (28.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> (28.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,169\u001b[0m (28.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> (28.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZF0tbCwYNmM",
        "outputId": "11846fa9-b7ea-46cd-c319-601e19e40a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7350 - loss: 0.4803 - val_accuracy: 0.9414 - val_loss: 0.1497\n",
            "Epoch 2/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9353 - loss: 0.1706 - val_accuracy: 0.9601 - val_loss: 0.1072\n",
            "Epoch 3/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9487 - loss: 0.1410 - val_accuracy: 0.9651 - val_loss: 0.0884\n",
            "Epoch 4/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9588 - loss: 0.1233 - val_accuracy: 0.9679 - val_loss: 0.0812\n",
            "Epoch 5/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9615 - loss: 0.1121 - val_accuracy: 0.9697 - val_loss: 0.0761\n",
            "Epoch 6/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9659 - loss: 0.0925 - val_accuracy: 0.9712 - val_loss: 0.0722\n",
            "Epoch 7/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9667 - loss: 0.0951 - val_accuracy: 0.9747 - val_loss: 0.0659\n",
            "Epoch 8/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9689 - loss: 0.0818 - val_accuracy: 0.9750 - val_loss: 0.0629\n",
            "Epoch 9/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9697 - loss: 0.0813 - val_accuracy: 0.9760 - val_loss: 0.0613\n",
            "Epoch 10/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9734 - loss: 0.0752 - val_accuracy: 0.9783 - val_loss: 0.0561\n",
            "Epoch 11/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9723 - loss: 0.0799 - val_accuracy: 0.9800 - val_loss: 0.0548\n",
            "Epoch 12/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9739 - loss: 0.0688 - val_accuracy: 0.9805 - val_loss: 0.0542\n",
            "Epoch 13/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9773 - loss: 0.0651 - val_accuracy: 0.9783 - val_loss: 0.0560\n",
            "Epoch 14/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9777 - loss: 0.0622 - val_accuracy: 0.9803 - val_loss: 0.0521\n",
            "Epoch 15/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9748 - loss: 0.0664 - val_accuracy: 0.9800 - val_loss: 0.0521\n",
            "Epoch 16/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9773 - loss: 0.0656 - val_accuracy: 0.9803 - val_loss: 0.0518\n",
            "Epoch 17/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9797 - loss: 0.0575 - val_accuracy: 0.9815 - val_loss: 0.0484\n",
            "Epoch 18/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9803 - loss: 0.0531 - val_accuracy: 0.9810 - val_loss: 0.0513\n",
            "Epoch 19/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9782 - loss: 0.0574 - val_accuracy: 0.9798 - val_loss: 0.0508\n",
            "Epoch 20/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9785 - loss: 0.0559 - val_accuracy: 0.9800 - val_loss: 0.0496\n",
            "Epoch 21/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9761 - loss: 0.0614 - val_accuracy: 0.9798 - val_loss: 0.0495\n",
            "Epoch 22/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9814 - loss: 0.0460 - val_accuracy: 0.9823 - val_loss: 0.0481\n",
            "Epoch 23/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9816 - loss: 0.0511 - val_accuracy: 0.9823 - val_loss: 0.0468\n",
            "Epoch 24/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9839 - loss: 0.0471 - val_accuracy: 0.9841 - val_loss: 0.0442\n",
            "Epoch 25/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9837 - loss: 0.0448 - val_accuracy: 0.9826 - val_loss: 0.0483\n",
            "Epoch 26/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9807 - loss: 0.0496 - val_accuracy: 0.9813 - val_loss: 0.0460\n",
            "Epoch 27/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9826 - loss: 0.0495 - val_accuracy: 0.9815 - val_loss: 0.0459\n",
            "Epoch 28/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9816 - loss: 0.0468 - val_accuracy: 0.9810 - val_loss: 0.0467\n",
            "Epoch 29/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 0.0503 - val_accuracy: 0.9815 - val_loss: 0.0484\n",
            "Epoch 30/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9851 - loss: 0.0415 - val_accuracy: 0.9815 - val_loss: 0.0459\n",
            "Epoch 31/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9832 - loss: 0.0421 - val_accuracy: 0.9821 - val_loss: 0.0469\n",
            "Epoch 32/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9836 - loss: 0.0440 - val_accuracy: 0.9836 - val_loss: 0.0479\n",
            "Epoch 33/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.0436 - val_accuracy: 0.9818 - val_loss: 0.0486\n",
            "Epoch 34/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9814 - loss: 0.0482 - val_accuracy: 0.9810 - val_loss: 0.0483\n",
            "Epoch 35/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9838 - loss: 0.0468 - val_accuracy: 0.9805 - val_loss: 0.0494\n",
            "Epoch 36/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9867 - loss: 0.0427 - val_accuracy: 0.9828 - val_loss: 0.0441\n",
            "Epoch 37/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9855 - loss: 0.0419 - val_accuracy: 0.9826 - val_loss: 0.0444\n",
            "Epoch 38/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9821 - loss: 0.0462 - val_accuracy: 0.9823 - val_loss: 0.0453\n",
            "Epoch 39/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9884 - loss: 0.0362 - val_accuracy: 0.9831 - val_loss: 0.0456\n",
            "Epoch 40/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9850 - loss: 0.0394 - val_accuracy: 0.9841 - val_loss: 0.0442\n",
            "Epoch 41/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9842 - loss: 0.0450 - val_accuracy: 0.9823 - val_loss: 0.0476\n",
            "Epoch 42/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.0402 - val_accuracy: 0.9836 - val_loss: 0.0463\n",
            "Epoch 43/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9879 - loss: 0.0358 - val_accuracy: 0.9808 - val_loss: 0.0492\n",
            "Epoch 44/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9853 - loss: 0.0441 - val_accuracy: 0.9833 - val_loss: 0.0451\n",
            "Epoch 45/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.0371 - val_accuracy: 0.9841 - val_loss: 0.0469\n",
            "Epoch 46/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.0408 - val_accuracy: 0.9843 - val_loss: 0.0458\n",
            "Epoch 47/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9882 - loss: 0.0351 - val_accuracy: 0.9846 - val_loss: 0.0426\n",
            "Epoch 48/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.0419 - val_accuracy: 0.9823 - val_loss: 0.0491\n",
            "Epoch 49/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.0334 - val_accuracy: 0.9838 - val_loss: 0.0468\n",
            "Epoch 50/50\n",
            "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9851 - loss: 0.0386 - val_accuracy: 0.9828 - val_loss: 0.0471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_input(file_path):\n",
        "    mfcc_features = extract_mfcc(file_path)\n",
        "    return np.expand_dims(mfcc_features, axis=0)  # Expand to match input shape of the model (1, 13)\n",
        "\n",
        "# Example: Make prediction on a new audio file\n",
        "file_path = \"/content/audio_data/eval/real/C_0059_05_B.wav\"\n",
        "prepared_input = prepare_input(file_path)\n",
        "prediction = model.predict(prepared_input)\n",
        "\n",
        "if prediction[0] > 0.5:\n",
        "    print(\"Predicted: Real\")\n",
        "else:\n",
        "    print(\"Predicted: Fake\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpNuX0QWYOUY",
        "outputId": "a5e9da37-6dc2-499f-d1b5-e4896c19c584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
            "Predicted: Fake\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: the above code is giving output as fake only on both fake and real data\n",
        "\n",
        "import numpy as np\n",
        "def prepare_input(file_path):\n",
        "    try:\n",
        "        mfcc_features = extract_mfcc(file_path)\n",
        "        return np.expand_dims(mfcc_features, axis=0)  # Expand to match input shape of the model (1, 13)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {file_path}: {e}\")\n",
        "        return None  # Return None to indicate an error\n",
        "\n",
        "# Example: Make prediction on a new audio file\n",
        "file_path = \"/content/audio_data/eval/real/C_0005_15_B.wav\"\n",
        "prepared_input = prepare_input(file_path)\n",
        "\n",
        "if prepared_input is not None:\n",
        "    prediction = model.predict(prepared_input)\n",
        "\n",
        "    if prediction[0] > 0.1:\n",
        "        print(\"Predicted: Real\")\n",
        "    else:\n",
        "        print(\"Predicted: Fake\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvwJR0_WYzwm",
        "outputId": "ca1657ac-b2f7-4256-f342-81b58d484b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "Predicted: Fake\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: i want tosee no. of fake and no. of real audios in dataset\n",
        "\n",
        "print(f\"Number of fake audio files: {sum(1 for label in labels if label == 0)}\")\n",
        "print(f\"Number of real audio files: {sum(1 for label in labels if label == 1)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUzm8GyAclcZ",
        "outputId": "51432c36-0a1f-4b85-f761-9e02f829c711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of fake audio files: 10660\n",
            "Number of real audio files: 2525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming you have 'audio_data' (MFCC features) and 'labels' (0: Fake, 1: Real)\n",
        "X = np.array(audio_data)  # MFCC features\n",
        "y = np.array(labels)  # Fake = 0, Real = 1\n",
        "\n",
        "# Split into Train and Test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Apply SMOTE to balance the training data\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Compute class weights after SMOTE\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_smote), y=y_train_smote)\n",
        "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
        "\n",
        "print(\"Class Weights:\", class_weights_dict)\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_train_smote = scaler.fit_transform(X_train_smote)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define a simple Deep Learning Model (ANN)\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_smote.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')  # Binary Classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with class weights\n",
        "history = model.fit(\n",
        "    X_train_smote, y_train_smote,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test),\n",
        "    class_weight=class_weights_dict\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Predictions\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_6lIdsJfg7I",
        "outputId": "ce84fb58-75c9-4618-a4cd-cf060c1d8f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: {0: 1.0, 1: 1.0}\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8331 - loss: 0.3616 - val_accuracy: 0.9613 - val_loss: 0.1000\n",
            "Epoch 2/20\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9698 - loss: 0.0903 - val_accuracy: 0.9681 - val_loss: 0.0797\n",
            "Epoch 3/20\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9801 - loss: 0.0600 - val_accuracy: 0.9757 - val_loss: 0.0636\n",
            "Epoch 4/20\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.0500 - val_accuracy: 0.9765 - val_loss: 0.0599\n",
            "Epoch 5/20\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 0.0379 - val_accuracy: 0.9788 - val_loss: 0.0599\n",
            "Epoch 6/20\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9864 - loss: 0.0365 - val_accuracy: 0.9814 - val_loss: 0.0544\n",
            "Epoch 7/20\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0324 - val_accuracy: 0.9780 - val_loss: 0.0645\n",
            "Epoch 8/20\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9903 - loss: 0.0285 - val_accuracy: 0.9807 - val_loss: 0.0534\n",
            "Epoch 9/20\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0247 - val_accuracy: 0.9799 - val_loss: 0.0553\n",
            "Epoch 10/20\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0244 - val_accuracy: 0.9822 - val_loss: 0.0604\n",
            "Epoch 11/20\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9921 - loss: 0.0250 - val_accuracy: 0.9788 - val_loss: 0.0585\n",
            "Epoch 12/20\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9929 - loss: 0.0217 - val_accuracy: 0.9788 - val_loss: 0.0622\n",
            "Epoch 13/20\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0203 - val_accuracy: 0.9784 - val_loss: 0.0599\n",
            "Epoch 14/20\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0179 - val_accuracy: 0.9791 - val_loss: 0.0577\n",
            "Epoch 15/20\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0155 - val_accuracy: 0.9803 - val_loss: 0.0605\n",
            "Epoch 16/20\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9939 - loss: 0.0179 - val_accuracy: 0.9791 - val_loss: 0.0613\n",
            "Epoch 17/20\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0168 - val_accuracy: 0.9791 - val_loss: 0.0626\n",
            "Epoch 18/20\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0159 - val_accuracy: 0.9810 - val_loss: 0.0635\n",
            "Epoch 19/20\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0135 - val_accuracy: 0.9814 - val_loss: 0.0614\n",
            "Epoch 20/20\n",
            "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0127 - val_accuracy: 0.9795 - val_loss: 0.0675\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9781 - loss: 0.0588\n",
            "Test Accuracy: 0.9795\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99      2132\n",
            "           1       0.96      0.93      0.95       505\n",
            "\n",
            "    accuracy                           0.98      2637\n",
            "   macro avg       0.97      0.96      0.97      2637\n",
            "weighted avg       0.98      0.98      0.98      2637\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "# Path to new audio file (Replace with actual file path)\n",
        "new_audio_path = '/content/audio_data/dev/real/B_0094_10_C.wav'\n",
        "\n",
        "# Function to extract MFCC from new audio file\n",
        "def extract_mfcc_from_audio(file_path):\n",
        "    audio, sr = librosa.load(file_path, sr=None)\n",
        "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
        "    mfcc = np.mean(mfcc, axis=1)  # Averaging over time frames\n",
        "    return mfcc\n",
        "\n",
        "# Extract MFCC features\n",
        "new_audio_features = extract_mfcc_from_audio(new_audio_path)\n",
        "\n",
        "# Reshape and normalize using the trained scaler\n",
        "new_audio_features = scaler.transform([new_audio_features])  # Keep it 2D\n",
        "\n",
        "# Predict using the trained model\n",
        "prediction = model.predict(new_audio_features)\n",
        "predicted_label = \"Real\" if prediction > 0.5 else \"Fake\"\n",
        "\n",
        "# Print output\n",
        "print(f\"Prediction: {predicted_label} (Confidence: {prediction[0][0]:.4f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHf_e3Cxi2EM",
        "outputId": "a003980d-12ea-4a58-96ad-f3bcda559685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "Prediction: Real (Confidence: 1.0000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yf2fYef5ja6L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}